{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T19:16:56.482547Z",
     "start_time": "2025-05-05T19:16:43.655567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import torch\n",
    "import yaml\n",
    "from src.dataset import create_dataloaders, ClinicalDataset, ImagingDataset\n",
    "from src.utils import load_and_preprocess_data, split_and_scale_data, set_random\n",
    "from src.train import train_and_evaluate_model\n",
    "from src.models import SimpleNN, ViTBinaryClassifier\n",
    "from monai.networks.nets import ViTAutoEnc\n",
    "\n",
    "\n",
    "import optuna"
   ],
   "id": "c40e37a3c5415d9d",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T19:16:56.504386Z",
     "start_time": "2025-05-05T19:16:56.486547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logging.basicConfig(\n",
    "    filename='training_logs.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "set_random()"
   ],
   "id": "da72264aab447e75",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T19:16:56.795590Z",
     "start_time": "2025-05-05T19:16:56.787906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "modality = \"imaging\"  # can be \"clinical\", \"imaging\", or \"multimodal\n",
    "\n",
    "assert modality in [\"clinical\", \"imaging\", \"multimodal\"], f\"Modality {modality} not supported\"\n",
    "\n",
    "# Common parameters\n",
    "\n",
    "with open(\"config.yml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "geo_csv_path = config['data'][\"geo_csv_path\"]\n",
    "curated_csv_path = config['data'][\"curated_csv_path\"]\n",
    "img_seq_path = config['data'][\"img_seq_path\"]\n",
    "pretrained_model_path  = config['data'][\"pretrained_model_path\"]\n",
    "label_col = config['data'][\"label_col\"]\n",
    "exclude_columns = config['data'][\"exclude_columns\"]"
   ],
   "id": "44057651c2b56bc6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T19:16:57.376068Z",
     "start_time": "2025-05-05T19:16:56.813192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if modality == \"imaging\":\n",
    "    pre_trained_model = ViTAutoEnc(\n",
    "    img_size=(64, 64, 64),\n",
    "    patch_size=8,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    num_layers=12,\n",
    "    num_heads=12,\n",
    "    hidden_size=384,\n",
    "    mlp_dim=2048\n",
    ")\n",
    "    state_dict = torch.load(pretrained_model_path, map_location=\"cpu\", weights_only=False)\n",
    "    if any(k.startswith(\"module.\") for k in state_dict.keys()):\n",
    "        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n",
    "    pre_trained_model.load_state_dict(state_dict, strict=False)\n",
    "    model = ViTBinaryClassifier\n",
    "\n",
    "    ds_cls = ImagingDataset\n",
    "    # model = resnet18\n",
    "\n",
    "    ds_cls_kwargs = {\"data_dir\": img_seq_path, \"is_gap\": False}\n",
    "    if isinstance(pre_trained_model, ViTAutoEnc):\n",
    "        ds_cls_kwargs[\"is_img\"] = True\n",
    "\n",
    "elif modality == \"clinical\":\n",
    "    ds_cls = ClinicalDataset\n",
    "    model = SimpleNN\n",
    "    ds_cls_kwargs = {\"columns_to_drop\": exclude_columns}\n",
    "\n",
    "elif modality == \"multimodal\":\n",
    "    pass  # TODO: Future implementation\n"
   ],
   "id": "84a2b16bc6fc4800",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done init\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-05-05T19:16:57.682721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 70\n",
    "embed_dim = 384\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 7)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
    "    random_state = trial.suggest_int(\"random_state\", 0, 10)\n",
    "    # n_heads = trial.suggest_categorical(\"n_heads\", [2, 4, 8])\n",
    "\n",
    "    geo_df = load_and_preprocess_data(geo_csv_path, curated_csv_path, label_col)\n",
    "    geo_df_train, geo_df_test = split_and_scale_data(geo_df, label_col, [col for col in geo_df.columns if col not in exclude_columns], random_state=random_state)\n",
    "\n",
    "    # Create dataloaders\n",
    "    dataloaders, feature_columns = create_dataloaders(\n",
    "        geo_df_train,\n",
    "        label_col,\n",
    "        exclude_columns,\n",
    "        batch_size,\n",
    "        dataset_cls=ds_cls,\n",
    "        dataset_kwargs=ds_cls_kwargs\n",
    "    )\n",
    "\n",
    "    # Model kwargs for model agnostic training\n",
    "    model_kwargs = {\n",
    "                    \"unfreeze_last_n\": num_layers,\n",
    "                    \"pretrained_model\": pre_trained_model,\n",
    "                    # \"num_heads_img\": n_heads,\n",
    "                    # \"num_layers_img\": num_layers,\n",
    "                    # \"hidden_size\": embed_dim,\n",
    "                    }\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    metrics = train_and_evaluate_model(\n",
    "        trial, dataloaders, feature_columns, geo_df_test, exclude_columns,\n",
    "        num_epochs=epochs, hidden_size=embed_dim, num_layers=num_layers,\n",
    "        batch_size=batch_size, learning_rate=learning_rate,\n",
    "        model_cls=model, model_kwargs=model_kwargs,\n",
    "        dataset_cls=ds_cls, dataset_kwargs=ds_cls_kwargs\n",
    "    )\n",
    "\n",
    "    # Return the validation AUC as the objective value\n",
    "    return metrics['auc']\n",
    "\n",
    "\n",
    "# Add stream handler of stdout to show the messages\n",
    "study_name = \"pretrained-encoder\"  # Unique identifier of the study.\n",
    "study = optuna.create_study(study_name=study_name, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=75)\n",
    "\n",
    "# Get the trial data as a DataFrame\n",
    "trial_data = study.trials_dataframe()\n",
    "\n",
    "\n",
    "# Save the trial data to a CSV file\n",
    "trial_data.to_csv(f'optuna_results/optuna_results_{modality}_cv.csv', index=False)"
   ],
   "id": "7ddfdd6f0189729f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2025-05-05 21:16:57,687]\u001B[0m A new study created in memory with name: pretrained-encoder\u001B[0m\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "\n"
   ],
   "id": "f641f79597b3f409",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
