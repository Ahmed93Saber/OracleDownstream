{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import logging\n",
    "from src.dataset import create_dataloaders, ClinicalDataset, ImagingDataset\n",
    "from src.utils import load_and_preprocess_data, split_and_scale_data\n",
    "from src.train import train_and_evaluate_model\n",
    "from src.models import SimpleNN, SimpleNNWithBatchNorm\n",
    "\n",
    "import optuna"
   ],
   "id": "c40e37a3c5415d9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "logging.basicConfig(\n",
    "    filename='training_logs.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ],
   "id": "da72264aab447e75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "modality = \"imaging\"  # can be \"clinical\", \"imaging\", or \"multimodal\n",
    "\n",
    "assert modality in [\"clinical\", \"imaging\", \"multimodal\"], f\"Modality {modality} not supported\"\n",
    "\n",
    "# Common parameters\n",
    "geo_csv_path = \"dataframes/threshold_df.csv\"\n",
    "curated_csv_path = \"dataframes/molab_df_curated.csv\"\n",
    "img_seq_path = \"representations/molab-hardy-leaf-97_embeddings.npy\"\n",
    "label_col = 'label-1RN-0Normal'\n",
    "exclude_columns = ['label-1RN-0Normal', 'Patient ID', 'id', 'BASELINE_TIME_POINT', \"CROSSING_TIME_POINT\", \"BASELINE_VOLUME\"]\n",
    "\n",
    "\n",
    "geo_df, exclude_columns = load_and_preprocess_data(geo_csv_path, curated_csv_path, label_col, exclude_columns)\n",
    "geo_df_train, geo_df_test = split_and_scale_data(geo_df, label_col, [col for col in geo_df.columns if col not in exclude_columns])"
   ],
   "id": "44057651c2b56bc6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if modality == \"imaging\":\n",
    "    ds_cls = ImagingDataset\n",
    "    model = SimpleNNWithBatchNorm\n",
    "    ds_cls_kwargs = {\"data_dir\": img_seq_path, \"is_gap\": True}\n",
    "\n",
    "elif modality == \"clinical\":\n",
    "    ds_cls = ClinicalDataset\n",
    "    model = SimpleNN\n",
    "    ds_cls_kwargs = {\"columns_to_drop\": exclude_columns}\n",
    "\n",
    "elif modality == \"multimodal\":\n",
    "    pass  # TODO: Future implementation\n"
   ],
   "id": "84a2b16bc6fc4800",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-29T09:16:35.664424Z",
     "start_time": "2025-04-29T09:13:47.621139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "epochs = 50\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [64, 128, 256, 512])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 1, 5)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1e-1)\n",
    "\n",
    "    # Create dataloaders\n",
    "    dataloaders, feature_columns = create_dataloaders(\n",
    "        geo_df_train,\n",
    "        label_col,\n",
    "        exclude_columns,\n",
    "        batch_size,\n",
    "        dataset_cls=ds_cls,\n",
    "        dataset_kwargs=ds_cls_kwargs\n",
    "    )\n",
    "\n",
    "    input_size = len(feature_columns) if modality == \"clinical\" else 384 # TODO: Remove hardcoded value\n",
    "\n",
    "    # Model kwargs for model agnostic training\n",
    "    model_kwargs = {\"input_size\": input_size, \"hidden_size\": hidden_size, \"num_layer\": num_layers}\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    metrics = train_and_evaluate_model(\n",
    "        trial, dataloaders, feature_columns, geo_df_test, exclude_columns,\n",
    "        num_epochs=epochs, hidden_size=hidden_size, num_layers=num_layers,\n",
    "        batch_size=batch_size, learning_rate=learning_rate,\n",
    "        model_cls=model, model_kwargs=model_kwargs\n",
    "    )\n",
    "\n",
    "    # Return the validation AUC as the objective value\n",
    "    return metrics['auc']\n",
    "\n",
    "\n",
    "# Add stream handler of stdout to show the messages\n",
    "study_name = \"pretrained-encoder\"  # Unique identifier of the study.\n",
    "study = optuna.create_study(study_name=study_name, direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=3)\n",
    "\n",
    "# Get the trial data as a DataFrame\n",
    "trial_data = study.trials_dataframe()\n",
    "\n",
    "# Save the trial data to a CSV file\n",
    "trial_data.to_csv(f'optuna_results/optuna_results_{modality}l_cv.csv', index=False)"
   ],
   "id": "5ed39499c50d5eb8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2025-04-29 11:13:47,629]\u001B[0m A new study created in memory with name: pretrained-encoder\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 41\u001B[39m\n\u001B[32m     39\u001B[39m study_name = \u001B[33m\"\u001B[39m\u001B[33mpretrained-encoder\u001B[39m\u001B[33m\"\u001B[39m  \u001B[38;5;66;03m# Unique identifier of the study.\u001B[39;00m\n\u001B[32m     40\u001B[39m study = optuna.create_study(study_name=study_name, direction=\u001B[33m\"\u001B[39m\u001B[33mmaximize\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m \u001B[43mstudy\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[38;5;66;03m# Get the trial data as a DataFrame\u001B[39;00m\n\u001B[32m     44\u001B[39m trial_data = study.trials_dataframe()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Envs\\FoundationModelCNN\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:400\u001B[39m, in \u001B[36mStudy.optimize\u001B[39m\u001B[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m    392\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m n_jobs != \u001B[32m1\u001B[39m:\n\u001B[32m    393\u001B[39m     warnings.warn(\n\u001B[32m    394\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m`n_jobs` argument has been deprecated in v2.7.0. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    395\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mThis feature will be removed in v4.0.0. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    396\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    397\u001B[39m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m    398\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m400\u001B[39m \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    401\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    402\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    403\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    404\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    405\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    406\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    407\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    408\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    409\u001B[39m \u001B[43m    \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    410\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Envs\\FoundationModelCNN\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001B[39m, in \u001B[36m_optimize\u001B[39m\u001B[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m     64\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     65\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs == \u001B[32m1\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m66\u001B[39m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     75\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     76\u001B[39m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     77\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     78\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     79\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m show_progress_bar:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Envs\\FoundationModelCNN\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001B[39m, in \u001B[36m_optimize_sequential\u001B[39m\u001B[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[39m\n\u001B[32m    160\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    162\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m163\u001B[39m     trial = \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    164\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m    165\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Envs\\FoundationModelCNN\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:213\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    210\u001B[39m     thread.start()\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m     value_or_values = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m exceptions.TrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    215\u001B[39m     \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[32m    216\u001B[39m     state = TrialState.PRUNED\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 27\u001B[39m, in \u001B[36mobjective\u001B[39m\u001B[34m(trial)\u001B[39m\n\u001B[32m     24\u001B[39m model_kwargs = {\u001B[33m\"\u001B[39m\u001B[33minput_size\u001B[39m\u001B[33m\"\u001B[39m: input_size, \u001B[33m\"\u001B[39m\u001B[33mhidden_size\u001B[39m\u001B[33m\"\u001B[39m: hidden_size, \u001B[33m\"\u001B[39m\u001B[33mnum_layer\u001B[39m\u001B[33m\"\u001B[39m: num_layers}\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Train and evaluate the model\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m27\u001B[39m metrics = \u001B[43mtrain_and_evaluate_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     28\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataloaders\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgeo_df_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     29\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     30\u001B[39m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     31\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel_cls\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel_kwargs\u001B[49m\n\u001B[32m     32\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     34\u001B[39m \u001B[38;5;66;03m# Return the validation AUC as the objective value\u001B[39;00m\n\u001B[32m     35\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m metrics[\u001B[33m'\u001B[39m\u001B[33mauc\u001B[39m\u001B[33m'\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\OracleProject\\src\\train.py:114\u001B[39m, in \u001B[36mtrain_and_evaluate_model\u001B[39m\u001B[34m(trial, dataloaders, feature_columns, test_df, exclude_columns, num_epochs, hidden_size, num_layers, learning_rate, batch_size, model_cls, model_kwargs)\u001B[39m\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m best_model_state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    112\u001B[39m     model.load_state_dict(best_model_state)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m test_metrics, test_ys = \u001B[43mevaluate_on_test_set\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    115\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_df\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_metrics\u001B[49m\n\u001B[32m    116\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    118\u001B[39m outputs_and_predictions[\u001B[33m\"\u001B[39m\u001B[33mlabels\u001B[39m\u001B[33m\"\u001B[39m].append(test_ys[\u001B[33m\"\u001B[39m\u001B[33mlabels\u001B[39m\u001B[33m\"\u001B[39m])\n\u001B[32m    119\u001B[39m outputs_and_predictions[\u001B[33m\"\u001B[39m\u001B[33mpredictions\u001B[39m\u001B[33m\"\u001B[39m].append(test_ys[\u001B[33m\"\u001B[39m\u001B[33mpredictions\u001B[39m\u001B[33m\"\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\OracleProject\\src\\train.py:151\u001B[39m, in \u001B[36mevaluate_on_test_set\u001B[39m\u001B[34m(model, test_df, exclude_columns, criterion, device, batch_size, test_metrics)\u001B[39m\n\u001B[32m    146\u001B[39m test_loader = DataLoader(\n\u001B[32m    147\u001B[39m     ClinicalDataset(test_df, columns_to_drop=exclude_columns),\n\u001B[32m    148\u001B[39m     batch_size=batch_size, shuffle=\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    149\u001B[39m )\n\u001B[32m    150\u001B[39m model.eval()\n\u001B[32m--> \u001B[39m\u001B[32m151\u001B[39m test_loss, test_metrics_fold, test_ys = \u001B[43mrun_epoch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    152\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_training\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[32m    153\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    155\u001B[39m test_metrics[\u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m].append(test_loss)\n\u001B[32m    156\u001B[39m test_metrics[\u001B[33m\"\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m\"\u001B[39m].append(test_metrics_fold[\u001B[33m\"\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m\"\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\OracleProject\\src\\train.py:22\u001B[39m, in \u001B[36mrun_epoch\u001B[39m\u001B[34m(model, loader, criterion, optimizer, device, is_training)\u001B[39m\n\u001B[32m     19\u001B[39m total_loss = \u001B[32m0\u001B[39m\n\u001B[32m     20\u001B[39m y_true, y_pred = [], []\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     24\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutputs\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Envs\\FoundationModelCNN\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    705\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    706\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    707\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m708\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    709\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    710\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    711\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    712\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    713\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    714\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Envs\\FoundationModelCNN\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    762\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    763\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m764\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    765\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    766\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Envs\\FoundationModelCNN\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Documents\\Envs\\FoundationModelCNN\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[39m, in \u001B[36m<listcomp>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\OracleProject\\src\\dataset.py:22\u001B[39m, in \u001B[36mClinicalDataset.__getitem__\u001B[39m\u001B[34m(self, index)\u001B[39m\n\u001B[32m     20\u001B[39m label = row[\u001B[33m'\u001B[39m\u001B[33mlabel-1RN-0Normal\u001B[39m\u001B[33m'\u001B[39m]\n\u001B[32m     21\u001B[39m features = row.drop(\u001B[38;5;28mself\u001B[39m.columns_to_drop).values.astype(\u001B[33m'\u001B[39m\u001B[33mfloat32\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m features_tensor = \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m label_tensor = torch.tensor(label, dtype=torch.float32)\n\u001B[32m     24\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m features_tensor, label_tensor\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n"
   ],
   "id": "634f8f5baa53c97f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
